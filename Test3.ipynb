{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce78f85-fcc4-45bb-9992-b2a0534c178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras._tf_keras.keras import layers, models\n",
    "from keras._tf_keras.keras.optimizers import Adam\n",
    "from keras._tf_keras.keras.losses import BinaryCrossentropy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c55790-f1eb-4f67-952c-75d556b48968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f2276c-de98-428b-8dfa-672bc6065c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "VOLUME_SIZE = (128, 128, 128)  # Resize volumes to 128x128x128\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee6bee9-1d80-42e9-be96-647d65d5ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 3D NIfTI file\n",
    "def load_nifti(file_path):\n",
    "    nifti = nib.load(file_path)\n",
    "    data = nifti.get_fdata()\n",
    "    return np.array(data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b393ab0e-4755-44e5-b3fb-cfd5a5e4a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_volume(volume, target_size):\n",
    "    \"\"\"\n",
    "    Resize and normalize a 3D volume.\n",
    "    \"\"\"\n",
    "    # Calculate zoom factors\n",
    "    zoom_factors = (\n",
    "        target_size[0] / volume.shape[0],\n",
    "        target_size[1] / volume.shape[1],\n",
    "        target_size[2] / volume.shape[2]\n",
    "    )\n",
    "    \n",
    "    # Resize the volume using scipy.ndimage.zoom\n",
    "    volume = zoom(volume, zoom_factors, order=1)  # order=1 for linear interpolation\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    volume = volume / np.max(volume)\n",
    "    \n",
    "    # Add channel dimension\n",
    "    volume = np.expand_dims(volume, axis=-1)\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95703768-72ce-478f-8e93-d01de50a4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_dataset(image_dir, label_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        label_path = os.path.join(label_dir, img_file)\n",
    "        \n",
    "        # Load 3D NIfTI files\n",
    "        img_volume = load_nifti(img_path)\n",
    "        mask_volume = load_nifti(label_path)\n",
    "        \n",
    "        # Preprocess volumes\n",
    "        img_volume = preprocess_volume(img_volume, VOLUME_SIZE)\n",
    "        mask_volume = preprocess_volume(mask_volume, VOLUME_SIZE)\n",
    "        \n",
    "        images.append(img_volume)\n",
    "        masks.append(mask_volume)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b3abb8-7327-4b45-8cc8-033254ca0c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model (3D U-Net)\n",
    "def unet_3d(input_size=(128, 128, 128, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    \n",
    "    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv3D(256, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    # Decoder\n",
    "    up5 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv4)\n",
    "    up5 = layers.concatenate([up5, conv3])\n",
    "    conv5 = layers.Conv3D(128, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = layers.Conv3D(128, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv5)\n",
    "    up6 = layers.concatenate([up6, conv2])\n",
    "    conv6 = layers.Conv3D(64, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = layers.Conv3D(64, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = layers.Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='same')(conv6)\n",
    "    up7 = layers.concatenate([up7, conv1])\n",
    "    conv7 = layers.Conv3D(32, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = layers.Conv3D(32, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Conv3D(1, 1, activation='sigmoid')(conv7)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81050ae1-a6b9-4d01-b85d-9f906cd131f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'C:/PEC-26/JIPMER-INTERN/Data/liver/labelTr/liver_0.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\nibabel\\loadsave.py:101\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/PEC-26/JIPMER-INTERN/Data/liver/labelTr/liver_0.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/PEC-26/JIPMER-INTERN/Data/liver/imagesTr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m label_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/PEC-26/JIPMER-INTERN/Data/liver/labelTr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(image_dir, label_dir)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load 3D NIfTI files\u001b[39;00m\n\u001b[0;32m     10\u001b[0m img_volume \u001b[38;5;241m=\u001b[39m load_nifti(img_path)\n\u001b[1;32m---> 11\u001b[0m mask_volume \u001b[38;5;241m=\u001b[39m \u001b[43mload_nifti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Preprocess volumes\u001b[39;00m\n\u001b[0;32m     14\u001b[0m img_volume \u001b[38;5;241m=\u001b[39m preprocess_volume(img_volume, VOLUME_SIZE)\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mload_nifti\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_nifti\u001b[39m(file_path):\n\u001b[1;32m----> 3\u001b[0m     nifti \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m nifti\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Python\\Lib\\site-packages\\nibabel\\loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'C:/PEC-26/JIPMER-INTERN/Data/liver/labelTr/liver_0.nii'"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "image_dir = \"C:/PEC-26/JIPMER-INTERN/Data/liver/imagesTr\"\n",
    "label_dir = \"C:/PEC-26/JIPMER-INTERN/Data/liver/labelTr\"\n",
    "images, masks = load_dataset(image_dir, label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c39768-6aab-4b99-ada2-7233cc6a8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427fa101-edd4-4920-aabd-99d9901767dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = unet_3d()\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02236bd9-b65a-4ea9-af72-61bbb1c40684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 50s/step - accuracy: 0.0186 - loss: 0.7140 - val_accuracy: 0.0200 - val_loss: 0.7021\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97a7fd9-5b3b-4525-ac1f-e7e7c179b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"3d_unet_liver_tumor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6140a08b-085a-4fc9-8e4b-93c70bc9ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3D segmentation output for a new volume\n",
    "def predict_3d_segmentation(model, input_volume):\n",
    "    input_volume = np.expand_dims(input_volume, axis=0)  # Add batch dimension\n",
    "    prediction = model.predict(input_volume)\n",
    "    prediction = (prediction > 0.5).astype(np.uint8)  # Apply threshold\n",
    "    return prediction[0]  # Remove batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62508bca-799b-475f-b336-77a7b0a74e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict segmentation for a validation volume\n",
    "sample_volume = X_val[0]\n",
    "predicted_mask = predict_3d_segmentation(model, sample_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d830e4a-7b3b-4fc3-8e4d-2b0eda7d0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted 3D mask as a NIfTI file\n",
    "def save_nifti(data, output_path):\n",
    "    nifti = nib.Nifti1Image(data, affine=np.eye(4))\n",
    "    nib.save(nifti, output_path)\n",
    "\n",
    "save_nifti(predicted_mask, \"predicted_3d_mask.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e892f4-db8f-4348-ad77-54c8e158f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"3d_unet_liver_tumor.h5\")\n",
    "\n",
    "# Use the model for predictions\n",
    "predictions = model.predict(X_test)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
